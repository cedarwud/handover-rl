{
  "timestamp": "2025-10-30T06:00:27.221041",
  "config": {
    "model_path": "output/dqn_level2_multi_obj_fixed/checkpoints/best_model.pth",
    "algorithm": "dqn",
    "num_episodes": 20,
    "seed": 42,
    "num_satellites": 97
  },
  "dqn_metrics": {
    "agent_name": "DQN Agent",
    "num_episodes": 20,
    "mean_reward": 0.777331064336872,
    "std_reward": 3.479785223985688,
    "min_reward": -2.4724712558191633,
    "max_reward": 13.945894492206685,
    "mean_handovers": 2.55,
    "std_handovers": 5.398842468529713,
    "mean_ping_pongs": 0.7,
    "mean_avg_rsrp": -52.55750274658203,
    "mean_episode_length": 51.05,
    "episode_rewards": [
      0.9456093193597527,
      13.945894492206685,
      -1.0,
      -1.0,
      2.4955713265502646,
      -1.0,
      3.0132220287804348,
      0.20915616956612437,
      -1.0,
      4.5440103668032865,
      -2.4724712558191633,
      -0.7109606998365133,
      -1.0,
      -1.0,
      0.10026020480260048,
      -0.20871663769081075,
      2.685045972014778,
      -1.0,
      -1.0,
      -1.0
    ],
    "episode_handovers": [
      4,
      23,
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      0,
      4,
      2,
      0,
      0,
      5,
      1,
      11,
      0,
      0,
      0
    ],
    "episode_ping_pongs": [
      1,
      3,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      0,
      2,
      0,
      7,
      0,
      0,
      0
    ]
  },
  "baseline_metrics": {
    "agent_name": "RSRP Baseline",
    "num_episodes": 20,
    "mean_reward": -0.5398168504055235,
    "std_reward": 1.1969492945571925,
    "min_reward": -3.0358664831218087,
    "max_reward": 2.4955713265502646,
    "mean_handovers": 1.05,
    "std_handovers": 1.4309088021254186,
    "mean_ping_pongs": 0.15,
    "mean_avg_rsrp": -52.4307975769043,
    "mean_episode_length": 16.05,
    "episode_rewards": [
      -0.5757673350686562,
      -3.0358664831218087,
      -1.0,
      -1.0,
      2.4955713265502646,
      -1.0,
      -0.4079141619931682,
      0.20915616956612437,
      -1.0,
      2.3969777650610267,
      -1.5778981910552357,
      -0.9262576439255752,
      -1.0,
      -1.0,
      0.020345160135661386,
      -0.6,
      0.20531638574089803,
      -1.0,
      -1.0,
      -1.0
    ],
    "episode_handovers": [
      1,
      5,
      0,
      0,
      0,
      0,
      2,
      0,
      0,
      2,
      4,
      2,
      0,
      0,
      2,
      1,
      2,
      0,
      0,
      0
    ],
    "episode_ping_pongs": [
      0,
      1,
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ]
  },
  "comparison": {
    "reward_improvement_percent": 243.99903666455057,
    "handover_reduction_percent": -142.85714285714283,
    "ping_pong_reduction_percent": -366.66666666666663,
    "dqn_mean_reward": 0.777331064336872,
    "baseline_mean_reward": -0.5398168504055235,
    "dqn_mean_handovers": 2.55,
    "baseline_mean_handovers": 1.05
  }
}