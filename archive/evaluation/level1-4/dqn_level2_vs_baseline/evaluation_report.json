{
  "timestamp": "2025-10-28T15:34:46.209139",
  "config": {
    "model_path": "output/dqn_level2/checkpoints/best_model.pth",
    "algorithm": "dqn",
    "num_episodes": 20,
    "seed": 42,
    "num_satellites": 97
  },
  "dqn_metrics": {
    "agent_name": "DQN Agent",
    "num_episodes": 20,
    "mean_reward": -1.2050000000000003,
    "std_reward": 1.0057211343110974,
    "min_reward": -3.700000000000001,
    "max_reward": -0.1,
    "mean_handovers": 3.65,
    "std_handovers": 7.8120099846326365,
    "mean_ping_pongs": 1.0,
    "mean_avg_rsrp": -52.6215934753418,
    "mean_episode_length": 76.95,
    "episode_rewards": [
      -3.700000000000001,
      -3.400000000000001,
      -1.0,
      -1.0,
      -1.0,
      -1.0,
      -1.1,
      -1.0,
      -1.0,
      -0.1,
      -0.5,
      -0.7999999999999999,
      -1.0,
      -1.0,
      -0.1,
      -3.3000000000000003,
      -0.1,
      -1.0,
      -1.0,
      -1.0
    ],
    "episode_handovers": [
      24,
      25,
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      0,
      2,
      5,
      0,
      0,
      0,
      16,
      0,
      0,
      0,
      0
    ],
    "episode_ping_pongs": [
      6,
      4,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      1,
      0,
      0,
      0,
      8,
      0,
      0,
      0,
      0
    ]
  },
  "baseline_metrics": {
    "agent_name": "RSRP Baseline",
    "num_episodes": 20,
    "mean_reward": -0.7300000000000001,
    "std_reward": 0.32264531609803354,
    "min_reward": -1.0,
    "max_reward": -0.2,
    "mean_handovers": 1.05,
    "std_handovers": 1.4309088021254186,
    "mean_ping_pongs": 0.15,
    "mean_avg_rsrp": -52.4307975769043,
    "mean_episode_length": 16.05,
    "episode_rewards": [
      -0.2,
      -0.8,
      -1.0,
      -1.0,
      -1.0,
      -1.0,
      -0.5,
      -1.0,
      -1.0,
      -0.5,
      -0.5,
      -0.30000000000000004,
      -1.0,
      -1.0,
      -0.30000000000000004,
      -0.2,
      -0.30000000000000004,
      -1.0,
      -1.0,
      -1.0
    ],
    "episode_handovers": [
      1,
      5,
      0,
      0,
      0,
      0,
      2,
      0,
      0,
      2,
      4,
      2,
      0,
      0,
      2,
      1,
      2,
      0,
      0,
      0
    ],
    "episode_ping_pongs": [
      0,
      1,
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      1,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ]
  },
  "comparison": {
    "reward_improvement_percent": -65.06849315068494,
    "handover_reduction_percent": -247.6190476190476,
    "ping_pong_reduction_percent": -566.6666666666667,
    "dqn_mean_reward": -1.2050000000000003,
    "baseline_mean_reward": -0.7300000000000001,
    "dqn_mean_handovers": 3.65,
    "baseline_mean_handovers": 1.05
  }
}