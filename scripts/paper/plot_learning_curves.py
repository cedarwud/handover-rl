#!/usr/bin/env python3
"""
Learning Curves ç”Ÿæˆå™¨ - æ¨™æº– RL è«–æ–‡åœ–è¡¨
å±•ç¤ºè¨“ç·´éç¨‹ä¸­çš„æ€§èƒ½æå‡

ç¬¦åˆ NeurIPS / ICML / ICLR æ¨™æº–æ ¼å¼

Usage:
    # å–®ä¸€æ–¹æ³•çš„å­¸ç¿’æ›²ç·š
    python scripts/plot_learning_curves.py \\
        --data training_level5_20min_final.log \\
        --output figures/learning_curve

    # å¤šå€‹æ–¹æ³•å°æ¯”
    python scripts/plot_learning_curves.py \\
        --data method1.log method2.log method3.log \\
        --labels "Ours" "Baseline 1" "Baseline 2" \\
        --output figures/learning_curve_comparison
"""

import argparse
import sys
from pathlib import Path
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.ndimage import uniform_filter1d

# å°å…¥æ¨£å¼é…ç½®
script_dir = Path(__file__).parent.parent  # scripts/
sys.path.insert(0, str(script_dir))
from paper.paper_style import (
    setup_paper_style, get_figure_size, save_figure,
    COLORS, COLOR_PALETTE, MARKERS
)
from extract_training_data import extract_episode_data


def smooth_curve(data: np.ndarray, window_size: int = 10) -> np.ndarray:
    """
    å¹³æ»‘æ›²ç·šï¼ˆä½¿ç”¨ç§»å‹•å¹³å‡ï¼‰

    Args:
        data: åŸå§‹æ•¸æ“š
        window_size: çª—å£å¤§å°

    Returns:
        å¹³æ»‘å¾Œçš„æ•¸æ“š
    """
    if len(data) < window_size:
        return data

    return uniform_filter1d(data, size=window_size, mode='nearest')


def plot_learning_curve(data_list: list,
                       labels: list = None,
                       output_file: str = 'figures/learning_curve',
                       smooth_window: int = 10,
                       show_std: bool = True,
                       x_axis: str = 'episode'):
    """
    ç”Ÿæˆ Learning Curve åœ–è¡¨

    Args:
        data_list: æ•¸æ“šåˆ—è¡¨ (list of DataFrames)
        labels: æ¨™ç±¤åˆ—è¡¨
        output_file: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        smooth_window: å¹³æ»‘çª—å£å¤§å°
        show_std: æ˜¯å¦é¡¯ç¤ºæ¨™æº–å·®å€åŸŸ
        x_axis: X è»¸é¡å‹ ('episode' æˆ– 'timestep')

    Returns:
        fig, ax: matplotlib Figure å’Œ Axes ç‰©ä»¶
    """

    setup_paper_style('neurips', font_scale=1.1)

    fig, ax = plt.subplots(figsize=get_figure_size())

    if labels is None:
        labels = [f'Method {i+1}' for i in range(len(data_list))]

    # ç¹ªè£½æ¯å€‹æ–¹æ³•çš„å­¸ç¿’æ›²ç·š
    for idx, (data, label) in enumerate(zip(data_list, labels)):
        episodes = data['episode'].values
        reward_mean = data['reward_mean'].values
        reward_std = data['reward_std'].values if show_std else None

        # å¹³æ»‘æ›²ç·š
        if smooth_window > 1:
            reward_mean_smooth = smooth_curve(reward_mean, smooth_window)
            if reward_std is not None:
                reward_std_smooth = smooth_curve(reward_std, smooth_window)
        else:
            reward_mean_smooth = reward_mean
            reward_std_smooth = reward_std

        # é¸æ“‡é¡è‰²å’Œæ¨£å¼
        color = COLOR_PALETTE[idx % len(COLOR_PALETTE)]
        marker = MARKERS[idx % len(MARKERS)]

        # ç¹ªè£½ä¸»æ›²ç·š
        ax.plot(episodes, reward_mean_smooth,
               color=color,
               linewidth=2.5,
               label=label,
               marker=marker,
               markersize=4,
               markevery=max(1, len(episodes) // 15),
               zorder=10 - idx)

        # ç¹ªè£½æ¨™æº–å·®å€åŸŸ
        if show_std and reward_std_smooth is not None:
            ax.fill_between(episodes,
                           reward_mean_smooth - reward_std_smooth,
                           reward_mean_smooth + reward_std_smooth,
                           color=color,
                           alpha=0.2,
                           zorder=10 - idx - 0.5)

    # è¨­å®šè»¸æ¨™ç±¤å’Œæ¨™é¡Œ
    xlabel = 'Episode' if x_axis == 'episode' else 'Training Steps'
    ax.set_xlabel(xlabel, fontsize=12, weight='bold')
    ax.set_ylabel('Episode Reward', fontsize=12, weight='bold')
    ax.set_title('Learning Curve', fontsize=13, weight='bold')

    # åœ–ä¾‹
    ax.legend(loc='best', framealpha=0.95, fontsize=10)

    # ç¶²æ ¼
    ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)

    # è¨­å®š X è»¸èµ·é»ç‚º 0
    ax.set_xlim(left=0)

    plt.tight_layout()
    save_figure(fig, output_file, formats=['pdf', 'png'])

    return fig, ax


def plot_multi_metric_curves(data: pd.DataFrame,
                            output_file: str = 'figures/multi_metric_curves',
                            smooth_window: int = 10):
    """
    ç”Ÿæˆå¤šæŒ‡æ¨™å­¸ç¿’æ›²ç·šï¼ˆReward + Loss + Handoversï¼‰

    Args:
        data: è¨“ç·´æ•¸æ“š (DataFrame)
        output_file: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        smooth_window: å¹³æ»‘çª—å£å¤§å°

    Returns:
        fig, axes: matplotlib Figure å’Œ Axes ç‰©ä»¶
    """

    setup_paper_style('neurips', font_scale=1.0)

    fig, axes = plt.subplots(3, 1, figsize=get_figure_size(height_ratio=1.2))

    episodes = data['episode'].values

    # ========================================
    # å­åœ– 1: Episode Reward
    # ========================================
    reward_mean = data['reward_mean'].values
    reward_std = data['reward_std'].values

    if smooth_window > 1:
        reward_mean_smooth = smooth_curve(reward_mean, smooth_window)
        reward_std_smooth = smooth_curve(reward_std, smooth_window)
    else:
        reward_mean_smooth = reward_mean
        reward_std_smooth = reward_std

    axes[0].plot(episodes, reward_mean_smooth,
                color=COLORS['primary'],
                linewidth=2.0,
                label='Mean Reward')

    axes[0].fill_between(episodes,
                         reward_mean_smooth - reward_std_smooth,
                         reward_mean_smooth + reward_std_smooth,
                         color=COLORS['primary'],
                         alpha=0.2,
                         label='Â±Ïƒ')

    axes[0].set_ylabel('Episode Reward', fontsize=10, weight='bold')
    axes[0].set_title('(a) Learning Progress: Episode Reward', fontsize=11, weight='bold')
    axes[0].legend(loc='best', fontsize=9)
    axes[0].grid(True, alpha=0.3)

    # ========================================
    # å­åœ– 2: Training Loss
    # ========================================
    loss = data['loss'].values

    if smooth_window > 1:
        loss_smooth = smooth_curve(loss, smooth_window)
    else:
        loss_smooth = loss

    axes[1].plot(episodes, loss_smooth,
                color=COLORS['secondary'],
                linewidth=2.0,
                label='Training Loss')

    # æ·»åŠ ç©©å®šæ€§é–¾å€¼ç·š
    axes[1].axhline(10, color=COLORS['danger'], linestyle='--',
                   linewidth=1.5, alpha=0.5, label='Stability threshold')

    axes[1].set_ylabel('Training Loss', fontsize=10, weight='bold')
    axes[1].set_title('(b) Training Stability: Loss', fontsize=11, weight='bold')
    axes[1].legend(loc='best', fontsize=9)
    axes[1].grid(True, alpha=0.3)

    # ========================================
    # å­åœ– 3: Handover Frequency
    # ========================================
    handovers_mean = data['handovers_mean'].values
    handovers_std = data['handovers_std'].values

    if smooth_window > 1:
        handovers_mean_smooth = smooth_curve(handovers_mean, smooth_window)
        handovers_std_smooth = smooth_curve(handovers_std, smooth_window)
    else:
        handovers_mean_smooth = handovers_mean
        handovers_std_smooth = handovers_std

    axes[2].plot(episodes, handovers_mean_smooth,
                color=COLORS['tertiary'],
                linewidth=2.0,
                label='Mean Handovers')

    axes[2].fill_between(episodes,
                         handovers_mean_smooth - handovers_std_smooth,
                         handovers_mean_smooth + handovers_std_smooth,
                         color=COLORS['tertiary'],
                         alpha=0.2,
                         label='Â±Ïƒ')

    axes[2].set_xlabel('Episode', fontsize=10, weight='bold')
    axes[2].set_ylabel('Handovers per Episode', fontsize=10, weight='bold')
    axes[2].set_title('(c) Handover Strategy: Frequency', fontsize=11, weight='bold')
    axes[2].legend(loc='best', fontsize=9)
    axes[2].grid(True, alpha=0.3)

    plt.tight_layout()
    save_figure(fig, output_file, formats=['pdf', 'png'])

    return fig, axes


def plot_convergence_analysis(data: pd.DataFrame,
                              output_file: str = 'figures/convergence_analysis',
                              convergence_threshold: float = 0.1):
    """
    æ”¶æ–‚æ€§åˆ†æåœ–

    Args:
        data: è¨“ç·´æ•¸æ“š
        output_file: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        convergence_threshold: æ”¶æ–‚é–¾å€¼ï¼ˆreward è®ŠåŒ–ç‡ï¼‰

    Returns:
        fig, axes: matplotlib Figure å’Œ Axes ç‰©ä»¶
    """

    setup_paper_style('neurips', font_scale=1.0)

    fig, axes = plt.subplots(2, 1, figsize=get_figure_size(height_ratio=0.8))

    episodes = data['episode'].values
    reward_mean = data['reward_mean'].values

    # è¨ˆç®—æ”¶æ–‚æ€§æŒ‡æ¨™
    # 1. ç§»å‹•å¹³å‡å·®ç•° (åˆ¤æ–·æ˜¯å¦æ”¶æ–‚)
    window = 50
    if len(reward_mean) >= window * 2:
        moving_avg = smooth_curve(reward_mean, window)
        moving_std = np.array([
            np.std(reward_mean[max(0, i-window):i+window])
            for i in range(len(reward_mean))
        ])

        # å­åœ– 1: Reward with moving average
        axes[0].plot(episodes, reward_mean,
                    color=COLORS['primary'],
                    alpha=0.3,
                    linewidth=1.0,
                    label='Raw Reward')

        axes[0].plot(episodes, moving_avg,
                    color=COLORS['primary'],
                    linewidth=2.5,
                    label=f'Moving Avg (window={window})')

        axes[0].set_ylabel('Episode Reward', fontsize=10, weight='bold')
        axes[0].set_title('(a) Reward Convergence', fontsize=11, weight='bold')
        axes[0].legend(loc='best', fontsize=9)
        axes[0].grid(True, alpha=0.3)

        # å­åœ– 2: Reward variance (åˆ¤æ–·ç©©å®šæ€§)
        axes[1].plot(episodes, moving_std,
                    color=COLORS['secondary'],
                    linewidth=2.0,
                    label='Reward Std Dev')

        # æ¨™è¨»æ”¶æ–‚å€åŸŸ
        if moving_std[-1] < moving_std[0] * convergence_threshold:
            axes[1].axhline(moving_std[-1], color=COLORS['success'],
                           linestyle='--', linewidth=1.5, alpha=0.7,
                           label='Converged level')

        axes[1].set_xlabel('Episode', fontsize=10, weight='bold')
        axes[1].set_ylabel('Reward Std Dev', fontsize=10, weight='bold')
        axes[1].set_title('(b) Training Stability', fontsize=11, weight='bold')
        axes[1].legend(loc='best', fontsize=9)
        axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    save_figure(fig, output_file, formats=['pdf', 'png'])

    return fig, axes


def main():
    parser = argparse.ArgumentParser(
        description='ç”Ÿæˆ Learning Curvesï¼ˆæ¨™æº– RL è«–æ–‡åœ–è¡¨ï¼‰'
    )
    parser.add_argument('--data', nargs='+', required=True,
                       help='è¨“ç·´æ—¥èªŒæª”æ¡ˆè·¯å¾‘ï¼ˆå¯å¤šå€‹ï¼‰')
    parser.add_argument('--labels', nargs='+', default=None,
                       help='æ–¹æ³•æ¨™ç±¤ï¼ˆèˆ‡ --data å°æ‡‰ï¼‰')
    parser.add_argument('--output', '-o', type=str,
                       default='figures/learning_curve',
                       help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼ˆä¸å«å‰¯æª”åï¼‰')
    parser.add_argument('--smooth', type=int, default=10,
                       help='å¹³æ»‘çª—å£å¤§å°ï¼ˆé è¨­ 10ï¼‰')
    parser.add_argument('--no-std', action='store_true',
                       help='ä¸é¡¯ç¤ºæ¨™æº–å·®å€åŸŸ')
    parser.add_argument('--multi-metric', action='store_true',
                       help='ç”Ÿæˆå¤šæŒ‡æ¨™åœ–ï¼ˆReward + Loss + Handoversï¼‰')
    parser.add_argument('--convergence', action='store_true',
                       help='ç”Ÿæˆæ”¶æ–‚æ€§åˆ†æåœ–')

    args = parser.parse_args()

    print("="*70)
    print("Learning Curves ç”Ÿæˆå™¨")
    print("="*70)

    # è¼‰å…¥æ•¸æ“š
    data_list = []
    for log_file in args.data:
        print(f"\nğŸ“– è¼‰å…¥æ•¸æ“š: {log_file}")
        data = extract_episode_data(Path(log_file))

        if len(data) == 0:
            print(f"âš ï¸  è­¦å‘Š: {log_file} ç„¡æœ‰æ•ˆæ•¸æ“šï¼Œè·³é")
            continue

        data_list.append(data)

    if len(data_list) == 0:
        print("âŒ éŒ¯èª¤: ç„¡æœ‰æ•ˆæ•¸æ“š")
        return 1

    # è¨­å®šæ¨™ç±¤
    if args.labels:
        if len(args.labels) != len(data_list):
            print(f"âš ï¸  è­¦å‘Š: æ¨™ç±¤æ•¸é‡ ({len(args.labels)}) èˆ‡æ•¸æ“šæ•¸é‡ ({len(data_list)}) ä¸ç¬¦")
            labels = args.labels[:len(data_list)] + \
                     [f'Method {i+1}' for i in range(len(args.labels), len(data_list))]
        else:
            labels = args.labels
    else:
        labels = ['Ours'] if len(data_list) == 1 else \
                 [f'Method {i+1}' for i in range(len(data_list))]

    # ç”Ÿæˆå­¸ç¿’æ›²ç·š
    print(f"\nğŸ¨ ç”Ÿæˆ Learning Curve...")
    plot_learning_curve(data_list, labels, args.output,
                       smooth_window=args.smooth,
                       show_std=not args.no_std)

    # ç”Ÿæˆå¤šæŒ‡æ¨™åœ–ï¼ˆåƒ…ç•¶åªæœ‰ä¸€å€‹æ•¸æ“šé›†æ™‚ï¼‰
    if args.multi_metric and len(data_list) == 1:
        print(f"\nğŸ¨ ç”Ÿæˆå¤šæŒ‡æ¨™åœ–...")
        multi_output = str(Path(args.output).parent / 'multi_metric_curves')
        plot_multi_metric_curves(data_list[0], multi_output, smooth_window=args.smooth)

    # ç”Ÿæˆæ”¶æ–‚æ€§åˆ†æåœ–
    if args.convergence and len(data_list) == 1:
        print(f"\nğŸ¨ ç”Ÿæˆæ”¶æ–‚æ€§åˆ†æåœ–...")
        conv_output = str(Path(args.output).parent / 'convergence_analysis')
        plot_convergence_analysis(data_list[0], conv_output)

    print("\n" + "="*70)
    print("âœ… Learning Curves ç”Ÿæˆå®Œæˆï¼")
    print("="*70)

    return 0


if __name__ == '__main__':
    exit(main())
