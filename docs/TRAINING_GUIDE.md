# Training Guide - é è¨ˆç®—ç³»çµ±è¨“ç·´æŒ‡å—

**æ—¥æœŸ**: 2025-11-08
**ç‰ˆæœ¬**: 3.0 (With Precompute System)

---

## âš ï¸ é‡è¦æé†’

### è¨“ç·´å‰å¿…é ˆå®Œæˆçš„æ­¥é©Ÿ

**1. ç”Ÿæˆé è¨ˆç®—è¡¨** (ä¸€æ¬¡æ€§ï¼Œç´„ 30 åˆ†é˜)

```bash
python scripts/generate_orbit_precompute.py \
  --start-time "2025-10-07 00:00:00" \
  --end-time "2025-10-14 00:00:00" \
  --output data/orbit_precompute_7days.h5 \
  --config configs/diagnostic_config.yaml
```

**2. å•Ÿç”¨é è¨ˆç®—æ¨¡å¼**

ç·¨è¼¯ `configs/diagnostic_config.yaml`:
```yaml
precompute:
  enabled: true  # æ”¹ç‚º true
  table_path: "data/orbit_precompute_7days.h5"
```

**3. ç¢ºèªå•Ÿç”¨æˆåŠŸ**

é‹è¡Œè¨“ç·´æ™‚æ‡‰è©²çœ‹åˆ°ï¼š
```
âœ… Precompute mode enabled - Training will be ~100x faster!
   Table: data/orbit_precompute_7days.h5
   Time range: 2025-10-07T00:00:00 to 2025-10-14T00:00:00
```

å¦‚æœçœ‹åˆ°ï¼š
```
âœ… Real-time calculation mode
âš ï¸  Training will be slow. Consider generating precompute table...
```
è¡¨ç¤º**æœªå•Ÿç”¨**é è¨ˆç®—ï¼Œè¨“ç·´æœƒéå¸¸æ…¢ï¼

---

## ğŸ¯ å¤šç´šè¨“ç·´ç­–ç•¥

ç³»çµ±æä¾› **7 å€‹è¨“ç·´ç´šåˆ¥** (Level 0-6)ï¼Œå¾å¿«é€Ÿæ¸¬è©¦åˆ°å®Œæ•´è¨“ç·´ã€‚

### è¨“ç·´ç´šåˆ¥ç¸½è¦½

| Level | åç¨± | Episodes | ç”¨é€” | æ¨è–¦ |
|-------|------|----------|------|------|
| **0** | Smoke Test | 10 | ç³»çµ±é©—è­‰ | é¦–æ¬¡é‹è¡Œ |
| **1** | Quick Validation | 50 | å¿«é€Ÿé©—è­‰ | â­ é–‹ç™¼ |
| **2** | Development | 200 | é–‹ç™¼è¿­ä»£ | èª¿åƒ |
| **3** | Validation | 500 | é©—è­‰æœ‰æ•ˆæ€§ | è«–æ–‡è‰ç¨¿ |
| **4** | Baseline | 1000 | å»ºç«‹åŸºç·š | å¯¦é©—å°æ¯” |
| **5** | Full Training | 1700 | å®Œæ•´è¨“ç·´ | è«–æ–‡å¯¦é©— |
| **6** | Long-term | 17000 | é•·æœŸè¨“ç·´ | â­ ç™¼è¡¨ |

---

## ğŸš€ æ¨è–¦è¨“ç·´æµç¨‹

### éšæ®µ 1: ç³»çµ±é©—è­‰ (Level 0)

**ç›®çš„**: ç¢ºèªä»£ç¢¼é‹è¡Œç„¡èª¤

```bash
python train.py \
  --algorithm dqn \
  --level 0 \
  --output-dir output/smoke_test \
  --config configs/diagnostic_config.yaml
```

**é æœŸæ™‚é–“** (with precompute):
- **ç´„ 1-2 åˆ†é˜** (10 episodes)
- å¯¦æ™‚æ¨¡å¼: ~10 åˆ†é˜

**æª¢æŸ¥é …ç›®**:
- âœ… é è¨ˆç®—è¡¨åŠ è¼‰æˆåŠŸ
- âœ… ç’°å¢ƒæ­£å¸¸é‹è¡Œ
- âœ… Agent å¯ä»¥è¨“ç·´
- âœ… Checkpoint æ­£å¸¸ä¿å­˜

---

### éšæ®µ 2: å¿«é€Ÿé©—è­‰ (Level 1) â­ æ¨è–¦

**ç›®çš„**: é©—è­‰è¨“ç·´é‚è¼¯ï¼Œè§€å¯Ÿå­¸ç¿’æ›²ç·š

```bash
python train.py \
  --algorithm dqn \
  --level 1 \
  --output-dir output/level1_quick \
  --config configs/diagnostic_config.yaml
```

**é æœŸæ™‚é–“** (with precompute):
- **ç´„ 5-10 åˆ†é˜** (50 episodes)
- å¯¦æ™‚æ¨¡å¼: ~8 å°æ™‚

**é©ç”¨å ´æ™¯**:
- âœ… æ¸¬è©¦æ–°çš„ hyperparameter
- âœ… æ¯”è¼ƒä¸åŒç®—æ³•
- âœ… å¿«é€Ÿè¿­ä»£æƒ³æ³•
- âœ… Debug reward function

**é—œéµæŒ‡æ¨™**:
- Episode reward è¶¨å‹¢
- Handover count è®ŠåŒ–
- Loss æ˜¯å¦æ”¶æ–‚
- æ˜¯å¦æœ‰ NaN/Inf

---

### éšæ®µ 3: é–‹ç™¼è¿­ä»£ (Level 2)

**ç›®çš„**: èª¿æ•´ hyperparameters å’Œ reward function

```bash
python train.py \
  --algorithm dqn \
  --level 2 \
  --output-dir output/level2_dev \
  --config configs/diagnostic_config.yaml
```

**é æœŸæ™‚é–“** (with precompute):
- **ç´„ 20-40 åˆ†é˜** (200 episodes)
- å¯¦æ™‚æ¨¡å¼: ~33 å°æ™‚

---

### éšæ®µ 4: é©—è­‰æœ‰æ•ˆæ€§ (Level 3)

**ç›®çš„**: é©—è­‰æ–¹æ³•æœ‰æ•ˆæ€§ï¼Œæº–å‚™è«–æ–‡è‰ç¨¿

```bash
python train.py \
  --algorithm dqn \
  --level 3 \
  --output-dir output/level3_validation \
  --config configs/diagnostic_config.yaml
```

**é æœŸæ™‚é–“** (with precompute):
- **ç´„ 50 åˆ†é˜ - 1.5 å°æ™‚** (500 episodes)
- å¯¦æ™‚æ¨¡å¼: ~83 å°æ™‚

**é—œéµæª¢æŸ¥**:
- èˆ‡ baseline æ¯”è¼ƒ
- Reward æå‡ç™¾åˆ†æ¯”
- Convergence åˆ†æ

---

### éšæ®µ 5: å»ºç«‹åŸºç·š (Level 4)

**ç›®çš„**: å»ºç«‹ç©©å®šåŸºç·šä¾›å¯¦é©—æ¯”è¼ƒ

```bash
python train.py \
  --algorithm dqn \
  --level 4 \
  --output-dir output/level4_baseline \
  --config configs/diagnostic_config.yaml
```

**é æœŸæ™‚é–“** (with precompute):
- **ç´„ 1.5-3 å°æ™‚** (1000 episodes)
- å¯¦æ™‚æ¨¡å¼: ~167 å°æ™‚ (7 å¤©)

---

### éšæ®µ 6: å®Œæ•´è¨“ç·´ (Level 5)

**ç›®çš„**: è«–æ–‡å¯¦é©—ï¼Œpublication-quality çµæœ

```bash
python train.py \
  --algorithm dqn \
  --level 5 \
  --output-dir output/level5_full \
  --config configs/diagnostic_config.yaml
```

**é æœŸæ™‚é–“** (with precompute):
- **ç´„ 3-5 å°æ™‚** (1700 episodes)
- å¯¦æ™‚æ¨¡å¼: ~283 å°æ™‚ (12 å¤©)

**è«–æ–‡ä½¿ç”¨**:
- ç”Ÿæˆ learning curves
- èˆ‡å¤šå€‹ baselines æ¯”è¼ƒ
- Ablation studies
- Statistical significance tests

---

### éšæ®µ 7: é•·æœŸè¨“ç·´ (Level 6) â­ ç™¼è¡¨æ¨è–¦

**ç›®çš„**: é”åˆ° 1M training steps (å­¸è¡“æ¨™æº–)

```bash
python train.py \
  --algorithm dqn \
  --level 6 \
  --output-dir output/level6_longterm \
  --config configs/diagnostic_config.yaml
```

**é æœŸæ™‚é–“** (with precompute):
- **ç´„ 28-34 å°æ™‚** (17000 episodes)
- å¯¦æ™‚æ¨¡å¼: ~2833 å°æ™‚ (118 å¤©ï¼)

**å­¸è¡“æ„ç¾©**:
- ç¬¦åˆ MuJoCo benchmark æ¨™æº– (1M steps)
- Peer review è¦æ±‚çš„å……åˆ†è¨“ç·´
- ç¢ºä¿å®Œå…¨æ”¶æ–‚

---

## ğŸ“Š æ™‚é–“å°æ¯” (å¯¦æ™‚ vs é è¨ˆç®—)

### æœªå•Ÿç”¨é è¨ˆç®— (èˆŠç³»çµ±)

| Level | Episodes | é ä¼°æ™‚é–“ | å¯¦éš› |
|-------|----------|----------|------|
| 0 | 10 | ~10 min | âŒ å¤ªæ…¢ |
| 1 | 50 | ~8 hours | âŒ å¤ªæ…¢ |
| 2 | 200 | ~33 hours | âŒ å¤ªæ…¢ |
| 3 | 500 | ~83 hours (3.5å¤©) | âŒ å¤ªæ…¢ |
| 4 | 1000 | ~167 hours (7å¤©) | âŒ å¤ªæ…¢ |
| 5 | 1700 | ~283 hours (12å¤©) | âŒ å¤ªæ…¢ |
| 6 | 17000 | ~2833 hours (118å¤©ï¼) | âŒ ä¸å¯è¡Œ |

### å•Ÿç”¨é è¨ˆç®— (æ–°ç³»çµ±) âœ…

| Level | Episodes | é ä¼°æ™‚é–“ | åŠ é€Ÿæ¯” |
|-------|----------|----------|--------|
| 0 | 10 | **~1-2 min** | **100x** |
| 1 | 50 | **~5-10 min** | **100x** |
| 2 | 200 | **~20-40 min** | **100x** |
| 3 | 500 | **~50 min - 1.5h** | **100x** |
| 4 | 1000 | **~1.5-3 hours** | **100x** |
| 5 | 1700 | **~3-5 hours** | **100x** |
| 6 | 17000 | **~28-34 hours** | **100x** |

**çµè«–**:
- Level 6 å¾ **118 å¤© â†’ 34 å°æ™‚** âœ… å¯è¡Œï¼
- å¿«é€Ÿè¿­ä»£æˆç‚ºå¯èƒ½

---

## ğŸ’¡ å»ºè­°çš„è¨“ç·´é †åº

### ç¬¬ä¸€æ¬¡è¨“ç·´

```bash
# Day 1: ç³»çµ±é©—è­‰å’Œå¿«é€Ÿæ¸¬è©¦
# 1. ç”Ÿæˆé è¨ˆç®—è¡¨ (30 min)
python scripts/generate_orbit_precompute.py \
  --start-time "2025-10-07 00:00:00" \
  --end-time "2025-10-14 00:00:00" \
  --output data/orbit_precompute_7days.h5 \
  --config configs/diagnostic_config.yaml

# 2. å•Ÿç”¨é è¨ˆç®—ï¼ˆç·¨è¼¯ configï¼‰
# è¨­ç½® precompute.enabled = true

# 3. Level 0: ç…™éœ§æ¸¬è©¦ (1-2 min)
python train.py --algorithm dqn --level 0 --output-dir output/smoke_test

# 4. Level 1: å¿«é€Ÿé©—è­‰ (5-10 min)
python train.py --algorithm dqn --level 1 --output-dir output/quick_val

# 5. æª¢æŸ¥çµæœ
python evaluate.py \
  --model output/quick_val/checkpoints/best_model.pth \
  --algorithm dqn \
  --episodes 20
```

### é–‹ç™¼éšæ®µ

```bash
# Level 2: èª¿æ•´ hyperparameters (20-40 min each)
python train.py --algorithm dqn --level 2 --output-dir output/lr_2e5
# ä¿®æ”¹ configï¼Œèª¿æ•´ learning_rate
python train.py --algorithm dqn --level 2 --output-dir output/lr_1e5
# æ¯”è¼ƒçµæœï¼Œé¸æ“‡æœ€ä½³é…ç½®
```

### è«–æ–‡æº–å‚™

```bash
# Level 3: åˆæ­¥é©—è­‰ (50 min - 1.5h)
python train.py --algorithm dqn --level 3 --output-dir output/paper_draft

# Level 5: å®Œæ•´å¯¦é©— (3-5 hours)
python train.py --algorithm dqn --level 5 --output-dir output/paper_exp1

# æ¯”è¼ƒ baselines
python evaluate.py --model output/paper_exp1/checkpoints/best_model.pth ...
```

### è«–æ–‡æäº¤å‰

```bash
# Level 6: æœ€çµ‚è¨“ç·´ (28-34 hours)
# å»ºè­°ï¼šè·‘éå¤œ + éš”å¤©
python train.py --algorithm dqn --level 6 --output-dir output/final_publication

# å®Œæ•´è©•ä¼°
python evaluate.py \
  --model output/final_publication/checkpoints/best_model.pth \
  --algorithm dqn \
  --episodes 100 \
  --output-dir evaluation/final
```

---

## ğŸ” ç›£æ§è¨“ç·´é€²åº¦

### TensorBoard (æ¨è–¦)

```bash
# å•Ÿå‹• TensorBoard
tensorboard --logdir output/

# ç€è¦½å™¨æ‰“é–‹
http://localhost:6006
```

### æ—¥èªŒæŸ¥çœ‹

```bash
# å¯¦æ™‚æŸ¥çœ‹è¨“ç·´æ—¥èªŒ
tail -f output/level1_quick/training.log

# æŸ¥çœ‹æœ€æ–°ç‹€æ…‹
python tools/check_progress.sh
```

### é—œéµæŒ‡æ¨™

ç›£æ§ä»¥ä¸‹æŒ‡æ¨™ï¼š
- **Episode Reward**: æ‡‰è©²ä¸Šå‡
- **Episode Length**: æ‡‰è©²è¶¨æ–¼ç©©å®š
- **Handover Count**: æ‡‰è©²æ¸›å°‘ï¼ˆé¿å… ping-pongï¼‰
- **Average RSRP**: æ‡‰è©²æå‡
- **Loss**: æ‡‰è©²æ”¶æ–‚
- **Epsilon**: æ‡‰è©²éæ¸›

---

## âš ï¸ å¸¸è¦‹å•é¡Œ

### Q1: è¨“ç·´æ™‚é–“æ¯”é æœŸé•·ï¼Ÿ

**æª¢æŸ¥**:
```python
# æŸ¥çœ‹æ—¥èªŒä¸­æ˜¯å¦æœ‰
âœ… Precompute mode enabled - Training will be ~100x faster!
```

å¦‚æœçœ‹åˆ°ï¼š
```
âœ… Real-time calculation mode
```
è¡¨ç¤º**æœªå•Ÿç”¨é è¨ˆç®—**ï¼

**è§£æ±º**:
1. æª¢æŸ¥ `configs/diagnostic_config.yaml` ä¸­ `precompute.enabled = true`
2. æª¢æŸ¥ `precompute.table_path` æ˜¯å¦æ­£ç¢º
3. ç¢ºèª HDF5 æ–‡ä»¶å­˜åœ¨ï¼š`ls -lh data/orbit_precompute_7days.h5`

### Q2: å‡ºç¾ "Timestamp out of range" éŒ¯èª¤ï¼Ÿ

**åŸå› **: Episode èµ·å§‹æ™‚é–“è¶…å‡ºé è¨ˆç®—è¡¨ç¯„åœ

**è§£æ±º**:
1. ç”Ÿæˆæ›´å¤§çš„é è¨ˆç®—è¡¨ï¼ˆä¾‹å¦‚ 14 å¤©ï¼‰
2. æˆ–èª¿æ•´ episode èµ·å§‹æ™‚é–“ç¯„åœ

### Q3: è¨“ç·´å¡ä½ä¸å‹•ï¼Ÿ

**æª¢æŸ¥**:
1. GPU ä½¿ç”¨ç‡ï¼š`nvidia-smi`
2. CPU ä½¿ç”¨ç‡ï¼š`htop`
3. æ—¥èªŒä¸­æ˜¯å¦æœ‰éŒ¯èª¤

### Q4: Loss çˆ†ç‚¸æˆ– NaNï¼Ÿ

**å·²å…§å»ºä¿è­·**:
- `enable_nan_check: true` (è‡ªå‹•æª¢æ¸¬)
- `q_value_clip: 100.0` (é˜²æ­¢çˆ†ç‚¸)
- Huber loss (æ›´ç©©å®š)

å¦‚æœä»å‡ºç¾å•é¡Œï¼š
1. é™ä½ learning rate
2. å¢åŠ  gradient clipping

---

## ğŸ“ è¨“ç·´æª¢æŸ¥æ¸…å–®

### é–‹å§‹è¨“ç·´å‰

- [ ] ç”Ÿæˆé è¨ˆç®—è¡¨
- [ ] å•Ÿç”¨é è¨ˆç®—æ¨¡å¼ï¼ˆ`config` ä¸­è¨­ç½®ï¼‰
- [ ] ç¢ºèª GPU å¯ç”¨ï¼ˆå¦‚æœ‰ï¼‰
- [ ] ç¢ºèªç£ç›¤ç©ºé–“è¶³å¤ ï¼ˆcheckpoints + logsï¼‰

### è¨“ç·´ä¸­

- [ ] ç›£æ§ TensorBoard
- [ ] æª¢æŸ¥ reward è¶¨å‹¢
- [ ] æª¢æŸ¥ loss æ”¶æ–‚
- [ ] å®šæœŸä¿å­˜ checkpoints

### è¨“ç·´å¾Œ

- [ ] è©•ä¼°æœ€ä½³æ¨¡å‹
- [ ] èˆ‡ baseline æ¯”è¼ƒ
- [ ] ç”Ÿæˆåœ–è¡¨ï¼ˆlearning curvesï¼‰
- [ ] ä¿å­˜çµæœåˆ° evaluation/

---

## ğŸ¯ ä¸‹ä¸€æ­¥

è¨“ç·´å®Œæˆå¾Œï¼š

1. **è©•ä¼°æ¨¡å‹**
   ```bash
   python evaluate.py \
     --model output/level5_full/checkpoints/best_model.pth \
     --algorithm dqn \
     --episodes 50
   ```

2. **ç”Ÿæˆè«–æ–‡åœ–è¡¨**
   ```bash
   python scripts/generate_paper_figures.sh
   ```

3. **æ¯”è¼ƒä¸åŒæ–¹æ³•**
   - DQN vs DDQN
   - DQN vs Baselines
   - Ablation studies

---

**æº–å‚™å¥½äº†å—ï¼Ÿé–‹å§‹è¨“ç·´ï¼** ğŸš€

å»ºè­°å¾ **Level 0 (Smoke Test)** é–‹å§‹ï¼Œç¢ºèªä¸€åˆ‡æ­£å¸¸å¾Œå†é€²è¡Œæ›´é•·çš„è¨“ç·´ã€‚
