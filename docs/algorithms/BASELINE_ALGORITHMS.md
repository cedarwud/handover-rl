# Baseline RL Algorithms for LEO Satellite Handover

**åŸºäº2023-2025å¹´æ–‡çŒ®è°ƒç ”çš„ç®—æ³•é€‰æ‹©ï¼ˆå·²éªŒè¯ï¼‰**

**åˆ›å»ºæ—¶é—´**: 2025-10-19
**æœ€åæ›´æ–°**: 2025-10-20 (æ˜ç¡®é¡¹ç›®èŒƒå›´)
**æ–‡çŒ®æ•°é‡**: 16ç¯‡ä¸»æµè®ºæ–‡
**éªŒè¯æ–¹æ³•**: WebSearch + å®é™…è®ºæ–‡é˜…è¯»

---

## ğŸ¯ é¡¹ç›®å®æ–½èŒƒå›´ï¼ˆæ˜ç¡®è¯´æ˜ï¼‰

**æœ¬é¡¹ç›®ç›®æ ‡**: å»ºç«‹ Baseline æ¡†æ¶ï¼Œä½œä¸ºæœªæ¥ç®—æ³•å¯¹æ¯”çš„åŸºç¡€

**å®æ–½èŒƒå›´** (Phase 1-2, 2-3 weeks):
- âœ… **1 ä¸ª RL baseline**: DQN (Deep Q-Network)
- âœ… **3 ä¸ª Rule-based baselines**:
  - Strongest RSRP (simple heuristic)
  - A4-based Strategy (3GPP A4 event + RSRP selection)
  - D2-based Strategy (3GPP D2 event + distance selection)

**æœªæ¥å¯¹æ¯”**:
- â­ **ç”¨æˆ·è‡ªå·±çš„ç®—æ³•** vs ä»¥ä¸Š 4 ä¸ª baselines
- âŒ **ä¸éœ€è¦å®ç°å…¶ä»– RL ç®—æ³•**ï¼ˆD3QNã€A2Cã€Rainbowã€SAC ç­‰ï¼‰

**Tier 2 è¯´æ˜**:
- ä»¥ä¸‹ Tier 2 éƒ¨åˆ†ä»…ä¸º**æ–‡çŒ®è°ƒç ”å‚è€ƒ**ï¼Œä¾›äº†è§£é¢†åŸŸç ”ç©¶ç°çŠ¶
- **ä¸åœ¨æœ¬é¡¹ç›®å®æ–½èŒƒå›´å†…**
- æ¡†æ¶è®¾è®¡æ”¯æŒæœªæ¥è½»æ¾æ‰©å±•ï¼Œä½†ç›®å‰ä¸éœ€è¦

---

## ğŸ“Š æ–‡çŒ®è°ƒç ”æ€»ç»“

### è°ƒç ”æ–¹æ³•
- **æ—¶é—´èŒƒå›´**: 2023-2025å¹´
- **æ¥æº**: IEEE, MDPI, arXiv, Frontiers, ScienceDirect
- **å…³é”®è¯**: LEO satellite handover, reinforcement learning, DQN, D3QN, PPO, A2C
- **è®ºæ–‡æ•°é‡**: 16ç¯‡ï¼ˆå«2025å¹´1æœˆæœ€æ–°è®ºæ–‡ï¼‰
- **éªŒè¯**: é€šè¿‡ WebSearch ç¡®è®¤ç®—æ³•å®é™…ç”¨äº handover

### âœ… æ ¸å¿ƒå‘ç°ï¼ˆå·²éªŒè¯ï¼‰

1. **DQN æ˜¯ LEO satellite handover çš„æ ‡å‡† baseline** â­â­â­â­â­
   - 10+ ç¯‡è®ºæ–‡æ˜ç¡®ç”¨äº handover
   - å­¦æœ¯ç•Œå…¬è®¤çš„å¯¹æ¯”åŸºå‡†

2. **D3QN æœ‰æ˜ç¡® handover åº”ç”¨è¯æ®** â­â­â­â­â­
   - "Routing Cost-Integrated Handover Strategy" (2024)
   - ç›´æ¥ç”¨äº multi-layer LEO mega-constellation

3. **PPO ä¸»è¦ç”¨äº satellite schedulingï¼Œä¸æ˜¯ handover** âš ï¸
   - Frontiers 2023 è¯´ "PPO is most stable" æ˜¯é’ˆå¯¹ **scheduling**
   - "Handover Protocol Learning" (2023) å‘ç° **IMPALA > PPO**
   - **æ— ç›´æ¥è¯æ®æ˜¾ç¤º PPO é€‚åˆ handover**

4. **Double DQN / Dueling DQN æ²¡æœ‰ç‹¬ç«‹ handover è®ºæ–‡**
   - å®ƒä»¬æ˜¯ D3QN çš„æŠ€æœ¯ç»„ä»¶
   - åº”è¯¥ç›´æ¥å®ç° D3QNï¼Œè€Œéåˆ†åˆ«å®ç°

5. **å¤§å¤šæ•°è®ºæ–‡åªç”¨ 1-2 ä¸ª RL baselines**
   - æ›´é‡è¦çš„æ˜¯å¯¹æ¯” traditional methods (A4, D2, strongest RSRP)
   - ç®—æ³•æ•°é‡ä¸æ˜¯é‡ç‚¹ï¼Œæ–¹æ³•è®ºåˆ›æ–°æ‰æ˜¯

---

## ğŸ¯ Tier 1: æ ¸å¿ƒ Baselineï¼ˆå¿…é¡»å®ç°ï¼‰

### 1. DQN (Deep Q-Network)

#### ä½¿ç”¨é¢‘ç‡: â­â­â­â­â­ (éå¸¸é«˜)

**ä¸ºä»€ä¹ˆå¿…é¡»å®ç°**:
- âœ… å‡ ä¹æ‰€æœ‰ LEO satellite handover è®ºæ–‡éƒ½ç”¨ DQN ä½œä¸º baseline
- âœ… å­¦æœ¯ç•Œå…¬è®¤çš„æ ‡å‡†å¯¹æ¯”æ–¹æ³•
- âœ… å®ç°ç®€å•ï¼Œè®­ç»ƒç¨³å®š
- âœ… é€‚åˆç¦»æ•£åŠ¨ä½œç©ºé—´ï¼ˆé€‰æ‹©å“ªé¢—å«æ˜Ÿï¼‰
- âœ… Off-policy æ ·æœ¬æ•ˆç‡é«˜ï¼ˆé‡è¦ï¼šLevel 5 éœ€è¦ 35 å°æ—¶ï¼‰

#### ä»£è¡¨è®ºæ–‡ï¼ˆå·²éªŒè¯ç”¨äº Handoverï¼‰

1. **Deep Q-Learning for Spectral Coexistence (2025å¹´1æœˆ)**
   - æ¥æº: IEEE æœ€æ–°è®ºæ–‡
   - åº”ç”¨: LEO/MEO å«æ˜Ÿé€šä¿¡ï¼ŒDQN ç®¡ç† gateway-user é“¾è·¯å¹²æ‰°
   - ç»“è®º: DQN é€‚åº” LEO é«˜ç§»åŠ¨æ€§ç¯å¢ƒ

2. **Deep Reinforcement Learning-based Satellite Handover Scheme (IEEE)**
   - åº”ç”¨: å«æ˜Ÿé€šä¿¡æ¢æ‰‹
   - ç»“è®º: DQN èƒ½å¤Ÿè‡ªé€‚åº”å­¦ä¹ æœ€ä¼˜æ¢æ‰‹ç­–ç•¥
   - å‚è€ƒ: IEEE Conference Publication 9613411

3. **Multi-dimensional Resource Allocation (2024å¹´3æœˆ)**
   - æ¥æº: Journal of Cloud Computing
   - ç»“è®º: DQN é€‚åº” LEO é«˜ç§»åŠ¨æ€§ï¼Œä¼˜åŒ–é¢‘è°±æ•ˆç‡ã€èƒ½æºæ•ˆç‡
   - DOI: 10.1186/s13677-024-00621-z

4. **Graph RL-Based Handover for LEO Satellites (2024å¹´7æœˆ, MDPI)**
   - ç®—æ³•: MPNN-DQNï¼ˆå›¾ç¥ç»ç½‘ç»œ + DQNï¼‰
   - ç»“è®º: ä¼˜äºä¼ ç»Ÿ DQN å’Œ DRL æ–¹æ³•

#### å®ç°ç‰¹ç‚¹
```python
# State: [RSRP, RSRQ, SINR, distance, elevation, doppler, ...]
# Action: Discrete(K+1) - stay or switch to satellite i
# Update: Per-step with experience replay
# Network: Standard MLP
```

#### æ€§èƒ½é¢„æœŸ
- Handover é¢‘ç‡: 10-30% of timesteps
- æ”¶æ•›é€Ÿåº¦: ~1500-2000 episodes
- æ ·æœ¬æ•ˆç‡: ä¸­ç­‰ï¼ˆå› ä¸º experience replayï¼‰

---

## ğŸ“š Tier 2: æ–‡çŒ®è°ƒç ”å‚è€ƒï¼ˆä»…ä¾›äº†è§£ï¼Œä¸åœ¨å®æ–½èŒƒå›´ï¼‰

**é‡è¦è¯´æ˜**:
- âš ï¸ ä»¥ä¸‹ç®—æ³•**ä¸åœ¨æœ¬é¡¹ç›®å®æ–½èŒƒå›´å†…**
- âš ï¸ è¿™éƒ¨åˆ†ä»…ä¸ºæ–‡çŒ®è°ƒç ”ç»“æœï¼Œä¾›äº†è§£ LEO satellite handover é¢†åŸŸç ”ç©¶ç°çŠ¶
- âš ï¸ ç”¨æˆ·å°†ä½¿ç”¨**è‡ªå·±çš„ç®—æ³•**ä¸ Phase 1-2 çš„ baselines è¿›è¡Œå¯¹æ¯”
- âš ï¸ ä¸éœ€è¦å®ç° D3QNã€A2Cã€Rainbow DQNã€SAC ç­‰ç®—æ³•

### 2. D3QN (Dueling Double DQN)

#### ä½¿ç”¨é¢‘ç‡: â­â­â­â­ (é«˜)

**ä¸ºä»€ä¹ˆå¯é€‰**:
- âœ… **æœ‰æ˜ç¡®çš„ handover è®ºæ–‡è¯æ®**ï¼ˆ2+ ç¯‡ï¼‰
- âœ… ç»“åˆ Double DQN å’Œ Dueling DQN çš„ä¼˜åŠ¿
- âš ï¸ å°æ–¼è­‰æ˜ "RL > Rule-based" ä¸¦éå¿…é ˆ
- âš ï¸ å¤§éƒ¨åˆ†è«–æ–‡åªç”¨ 1 å€‹ RL ç®—æ³•

**ä½¿ç”¨å ´æ™¯**:
- å¦‚éœ€è­‰æ˜ "ç‚ºä»€éº¼é¸ DQN è€Œéå…¶ä»– RL ç®—æ³•"
- å¦‚éœ€å±•ç¤ºç®—æ³•æ”¹é€²æ•ˆæœï¼ˆDQN â†’ D3QNï¼‰
- å¦‚æœ‰é¡å¤–æ™‚é–“å¯å¯¦ç¾

#### ä»£è¡¨è«–æ–‡ï¼ˆå·²é©—è­‰ç”¨æ–¼ Handoverï¼‰

1. **Routing Cost-Integrated Handover Strategy (2024)** â­ æ ¸å¿ƒè­‰æ“š
   - æ¥æº: Chinese Journal of Aeronautics (October 2024)
   - ç®—æ³•: Dueling Double Deep Q Network (D3QN)
   - åº”ç”¨: Multi-layer LEO mega-constellation (Starlink è§„æ¨¡)
   - æ€§èƒ½:
     - ç«¯åˆ°ç«¯å»¶è¿Ÿå‡å°‘ 8.2%
     - æŠ–åŠ¨å‡å°‘ 59.5%
   - ç»“è®º: D3QN ä¼˜åŒ–è·¯ç”±æˆæœ¬å’Œæ¢æ‰‹å†³ç­–

2. **Age-Oriented Satellite Handover Strategy (2024)**
   - ç®—æ³•: D3QN
   - åº”ç”¨: ä¿¡æ¯æ–°é²œåº¦ä¼˜åŒ–
   - ç»“è®º: D3QN æœ€å°åŒ– peak age of information

#### æ ¸å¿ƒæŠ€æœ¯

**Double Q-learning**ï¼ˆè§£å†³ Q å€¼è¿‡ä¼°è®¡ï¼‰:
```python
# DQN: ç”¨åŒä¸€ä¸ªç½‘ç»œé€‰æ‹©å’Œè¯„ä¼°
q_targets = rewards + gamma * target_q_values.max(1)[0]

# Double DQN: ç”¨ online network é€‰æ‹©ï¼Œtarget network è¯„ä¼°
best_actions = online_network(next_states).argmax(1)
q_targets = rewards + gamma * target_network(next_states).gather(1, best_actions)
```

**Dueling Architecture**ï¼ˆåˆ†ç¦» Value å’Œ Advantageï¼‰:
```python
# Standard DQN: ç›´æ¥è¾“å‡º Q(s,a)
Q(s,a) = network(s)

# Dueling DQN: åˆ†ç¦» V(s) å’Œ A(s,a)
V(s) = value_stream(features)
A(s,a) = advantage_stream(features)
Q(s,a) = V(s) + (A(s,a) - mean(A(s,a)))
```

#### å®ç°å»ºè®®
- åŸºäº DQN ä»£ç ä¿®æ”¹ï¼ˆ2-3 å¤©ï¼‰
- ä¸éœ€è¦åˆ†åˆ«å®ç° Double DQN å’Œ Dueling DQN
- ç›´æ¥å®ç°ç»„åˆç‰ˆæœ¬æ›´é«˜æ•ˆ

#### ROI åˆ†æ
- **å®ç°æ—¶é—´**: 2-3 days
- **è°ƒå‚æ—¶é—´**: 1 week
- **å­¦æœ¯ä»·å€¼**: â­â­â­â­ (å¦‚éœ€è­‰æ˜ DQN é¸æ“‡åˆç†æ€§)
- **å»ºè®®**: å¯é¸ï¼Œéå¿…é ˆ

---

### 3. A2C (Advantage Actor-Critic)

#### ä½¿ç”¨é¢‘ç‡: â­â­â­ (ä¸­ç­‰)

**ä¸ºä»€ä¹ˆå¯é€‰**:
- âœ… æœ‰ 1 ç¯‡ handover è®ºæ–‡è¯æ®ï¼ˆ2025ï¼‰
- âœ… Policy gradient æ–¹æ³•ï¼ˆæä¾›ä¸åŒè§†è§’ï¼‰
- âš ï¸ Frontiers 2023 è­¦å‘Š: "high variance"
- âš ï¸ On-policyï¼ˆè®­ç»ƒæˆæœ¬é«˜äº DQNï¼‰

#### ä»£è¡¨è®ºæ–‡ï¼ˆå·²éªŒè¯ç”¨äº Handoverï¼‰

1. **LEO Satellite Handover Using A2C in Giant Constellation (2025)** â­ æ ¸å¿ƒè¯æ®
   - åº”ç”¨: Giant constellation network
   - ç®—æ³•: Advantage Actor-Critic (A2C)
   - è€ƒè™‘å› ç´ : å¯ç”¨å¸¦å®½ã€ä»°è§’ã€RSRPã€æ½œåœ¨æœåŠ¡æ—¶é—´ã€æœåŠ¡è´¨é‡
   - å»ºæ¨¡: Multi-Agent Markov Decision Process (MAMDP)

2. **Handover Protocol Learning for LEO Satellite Networks (2023)**
   - å¯¹æ¯”: IMPALA, DQN, A3C, PPO
   - ç»“è®º: IMPALA > A3C > PPOï¼ˆA2C/A3C è¡¨ç°ä¸­ç­‰ï¼‰

3. **Comparative Analysis (Frontiers 2023 - Scheduling, not Handover)**
   - ç»“è®º: "A2C typically able to produce high-performing policies, but with **relatively high variance**"

#### å®ç°ç‰¹ç‚¹
- Actor-Critic æ¶æ„
- A3C: å¼‚æ­¥å¹¶è¡Œè®­ç»ƒï¼ˆå¯é€‰ï¼‰
- é€‚åˆä½œä¸º policy-based æ–¹æ³•å¯¹æ¯”

#### ROI åˆ†æ
- **å®ç°æ—¶é—´**: 3-5 å¤©
- **è°ƒå‚æ—¶é—´**: 1-2 å‘¨
- **å­¦æœ¯ä»·å€¼**: â­â­â­ï¼ˆå±•ç¤º policy gradient æ–¹æ³•ï¼‰
- **å»ºè®®**: å¦‚æœæ—¶é—´å……è£•å¯å®ç°ï¼Œå¦åˆ™å¯è·³è¿‡

---

### 4. Rainbow DQN

#### ä½¿ç”¨é¢‘ç‡: â­â­ (ä½)

**ä¸ºä»€ä¹ˆäº†è§£**:
- âœ… æœ‰ 1 ç¯‡ handover è®ºæ–‡è¯æ®ï¼ˆ2024ï¼‰
- âœ… ç»“åˆå¤šç§ DQN æ”¹è¿›ï¼ˆç†è®ºä¸Šæ€§èƒ½æœ€ä¼˜ï¼‰
- âš ï¸ å®ç°å¤æ‚ï¼ˆ6+ ç»„ä»¶ï¼‰ï¼Œè°ƒè¯•å›°éš¾
- âš ï¸ æŠ•èµ„å›æŠ¥ç‡ä½

#### ä»£è¡¨è®ºæ–‡ï¼ˆå·²éªŒè¯ç”¨äº Handoverï¼‰

1. **Joint Traffic Prediction and Handover Design with Rainbow DQN (MDPI 2024)** â­ æ ¸å¿ƒè¯æ®
   - ç®—æ³•: LSTM + Attention-Enhanced Rainbow DQN
   - åº”ç”¨: LEO satellite networks æµé‡é¢„æµ‹å’Œæ¢æ‰‹
   - ç‰¹ç‚¹: æ³¨æ„åŠ›æœºåˆ¶å¢å¼º
   - ç»“è®º: ç»“åˆäº¤é€šé¢„æµ‹å’Œæ¢æ‰‹å†³ç­–

#### å®ç°ç»„ä»¶ï¼ˆå¤æ‚åº¦é«˜ï¼‰
- Double Q-learning
- Dueling networks
- Prioritized experience replay
- Multi-step learning
- Distributional RL
- Noisy nets

#### ROI åˆ†æ
- **å®ç°æ—¶é—´**: 7-10 å¤©
- **è°ƒå‚æ—¶é—´**: 2-3 å‘¨
- **å­¦æœ¯ä»·å€¼**: â­â­ï¼ˆå±•ç¤ºç®—æ³•å¤æ‚åº¦ vs æ€§èƒ½ï¼‰
- **å»ºè®®**: é™¤éç ”ç©¶æ·±åº¦éœ€è¦ï¼Œå¦åˆ™ä¸æ¨è

---

### 5. SAC (Soft Actor-Critic)

#### ä½¿ç”¨é¢‘ç‡: â­â­â­ (ä¸­ç­‰)

**ä¸ºä»€ä¹ˆå…³æ³¨**:
- âœ… æœ‰ 1 ç¯‡ handover è®ºæ–‡è¯æ®ï¼ˆ2024ï¼‰
- âœ… Maximum entropy frameworkï¼ˆé¼“åŠ±æ¢ç´¢ï¼‰
- âš ï¸ åŸç‰ˆ SAC ä¸ºè¿ç»­åŠ¨ä½œè®¾è®¡ï¼ˆéœ€æ”¹é€ ï¼‰
- âš ï¸ å®ç°å¤æ‚åº¦é«˜

#### ä»£è¡¨è®ºæ–‡ï¼ˆå·²éªŒè¯ç”¨äº Handoverï¼‰

1. **Nash-SAC for LEO Satellite Handover (arXiv 2024å¹´2æœˆ)** â­ æ ¸å¿ƒè¯æ®
   - ç®—æ³•: Nash Soft Actor-Critic
   - åº”ç”¨: Flying vehicles çš„ LEO æ¢æ‰‹
   - æ€§èƒ½ï¼ˆvs Nash-DQNï¼‰:
     - å‡å°‘æ¢æ‰‹æ¬¡æ•°: **16%**
     - æ”¹å–„é˜»å¡ç‡: **18%**
     - æå‡ç½‘ç»œæ•ˆç”¨: **48%**
   - ç»“è®º: SAC çš„ maximum entropy æ¡†æ¶æ¯” DQN æœ‰æ›´å¥½æ¢ç´¢

#### ç¦»æ•£åŒ–æŒ‘æˆ˜
```python
# SAC åŸç‰ˆ: è¿ç»­åŠ¨ä½œ (Gaussian policy)
action = policy_network(state) + noise

# ç¦»æ•£ç‰ˆæœ¬éœ€è¦:
# - Categorical distribution
# - Gumbel-Softmax trick
# æˆ–ä½¿ç”¨ Discrete SAC (Chris Bamford 2019)
```

#### ROI åˆ†æ
- **å®ç°æ—¶é—´**: 5-7 å¤©ï¼ˆéœ€ç¦»æ•£åŒ–æ”¹é€ ï¼‰
- **è°ƒå‚æ—¶é—´**: 2-3 å‘¨
- **å­¦æœ¯ä»·å€¼**: â­â­â­ï¼ˆå±•ç¤º maximum entropy RLï¼‰
- **å»ºè®®**: é«˜çº§ç ”ç©¶å¯é€‰ï¼ŒåŸºç¡€è®ºæ–‡å¯è·³è¿‡

---

## âŒ Tier 3: ä¸æ¨èçš„ç®—æ³•ï¼ˆæ—  Handover è¯æ®æˆ–ä¸é€‚ç”¨ï¼‰

### 1. PPO (Proximal Policy Optimization)

#### ä½¿ç”¨é¢‘ç‡: â­ (ç”¨äº Schedulingï¼Œä¸æ˜¯ Handover)

**ä¸ºä»€ä¹ˆä¸æ¨è**:
- âŒ **Frontiers 2023 è¯´ "PPO is most stable" æ˜¯é’ˆå¯¹ satellite schedulingï¼Œä¸æ˜¯ handover**
- âŒ "Handover Protocol Learning" (2023) å‘ç° **IMPALA > A3C > PPO**ï¼ˆPPO è¡¨ç°å·®ï¼‰
- âŒ æ— ç›´æ¥è¯æ®æ˜¾ç¤º PPO é€‚åˆ handover
- âŒ On-policy è®­ç»ƒæˆæœ¬é«˜ï¼ˆLevel 5 å¯èƒ½éœ€è¦ 50+ å°æ—¶ï¼‰

#### æ··æ·†æ¥æºåˆ†æ

**Frontiers 2023 è®ºæ–‡**:
- æ ‡é¢˜: "Comparative Analysis of RL Algorithms for **Satellite Scheduling**"
- åº”ç”¨: Earth-observing satellite schedulingï¼ˆä»»åŠ¡è°ƒåº¦ï¼‰
- **ä¸æ˜¯**: Satellite handoverï¼ˆæ¢æ‰‹å†³ç­–ï¼‰
- ç»“è®º: PPO åœ¨ scheduling ä»»åŠ¡ä¸­ç¨³å®šï¼Œä½†ä¸ä»£è¡¨é€‚åˆ handover

**Handover Protocol Learning 2023**:
- å¯¹æ¯”: IMPALA, DQN, A3C, PPO
- ç»“è®º: "IMPALA exhibits better performance compared to A3C and PPO in terms of stable convergence"
- **PPO è¡¨ç°ä¸å¦‚ IMPALA å’Œ DQN**

#### ç»“è®º
- âš ï¸ PPO å¯èƒ½ä¸é€‚åˆ LEO satellite handover
- âš ï¸ å¦‚æœè¦å®ç°ï¼Œåº”è¯¥ä½œä¸º Tier 3 å¯é€‰ï¼Œè€Œé Tier 1 å¿…é¡»
- âœ… å»ºè®®: **è·³è¿‡ PPOï¼Œä¸“æ³¨äº DQN + D3QN**

---

### 2. Double DQN / Dueling DQNï¼ˆå•ç‹¬å®ç°ï¼‰

**ä¸ºä»€ä¹ˆä¸å•ç‹¬å®ç°**:
- âŒ æ²¡æœ‰æ‰¾åˆ° LEO satellite handover çš„ç‹¬ç«‹è®ºæ–‡
- âŒ å®ƒä»¬æ˜¯ D3QN çš„æŠ€æœ¯ç»„ä»¶
- âœ… åº”è¯¥ç›´æ¥å®ç° D3QNï¼ˆåŒ…å«ä¸¤è€…ï¼‰

---

### 3. å…¶ä»–ä¸æ¨èçš„ç®—æ³•

**Continuous Algorithms (åŸç‰ˆ SAC, TD3, DDPG)**:
- âŒ æ¢æ‰‹æœ¬è´¨æ˜¯ç¦»æ•£å†³ç­–ï¼ˆé€‰æ‹©å“ªé¢—å«æ˜Ÿï¼‰
- âŒ å¼ºè¡Œæ”¹æˆè¿ç»­åŠ¨ä½œæ²¡æœ‰æ˜æ˜¾å¥½å¤„

**Model-Based RL (Dyna-Q, MBPO)**:
- âŒ éœ€è¦å­¦ä¹ è½¨é“æ¨¡å‹ï¼ˆæˆ‘ä»¬å·²æœ‰ SGP4ï¼‰
- âŒ è®¡ç®—é‡å¤§ï¼ŒæŠ•èµ„å›æŠ¥ç‡ä½

**Multi-Agent RL (MADQN, MADDPG, QMIX)**:
- âŒ å•ç”¨æˆ·åœºæ™¯ä¸éœ€è¦
- âŒ å®ç°å¤æ‚åº¦å¤ªé«˜

---

## ğŸ“Š ç®—æ³•å¯¹æ¯”è¡¨ï¼ˆåŸºäºæ–‡çŒ®éªŒè¯ï¼‰

| ç®—æ³• | Handover è®ºæ–‡æ•° | ç¨³å®šæ€§ | æ€§èƒ½ | å®ç°éš¾åº¦ | è®­ç»ƒæˆæœ¬ | æ¨èåº¦ |
|------|----------------|--------|------|---------|---------|--------|
| **DQN** | 10+ | â­â­â­ | â­â­â­â­ | â­ Easy | ä¸­ | âœ… **å¿…é¡»** |
| **D3QN** | 2+ | â­â­â­â­ | â­â­â­â­â­ | â­â­ Medium | ä¸­ | âš ï¸ å¯é€‰ |
| **A2C** | 1 | â­â­â­ | â­â­â­â­ | â­â­ Medium | é«˜ | âš ï¸ å¯é€‰ |
| **Rainbow** | 1 | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ Very Hard | é«˜ | âš ï¸ å¯é€‰ |
| **SAC** | 1 | â­â­â­â­ | â­â­â­â­ | â­â­â­ Hard | ä¸­ | âš ï¸ å¯é€‰ |
| **PPO** | 0 (Scheduling) | ? | ? | â­â­ Medium | å¾ˆé«˜ | âŒ ä¸æ¨è |

**æ³¨**: "è®­ç»ƒæˆæœ¬" è€ƒè™‘äº† Level 5 (35 hours) çš„å®é™…æƒ…å†µ

---

## ğŸ¯ å®æ–½å»ºè®®ï¼ˆBaseline æ¡†æ¶ï¼‰

### âœ… æ¨èæ–¹æ¡ˆ: DQN + Rule-based Baselinesï¼ˆå®Œæ•´æ¡†æ¶ï¼‰â­

**ç›®æ ‡**: å»ºç«‹å®Œæ•´çš„ baseline æ¡†æ¶ï¼Œä½œç‚ºæœªä¾†ç®—æ³•å°æ¯”çš„åŸºç¤

**å¿…é¡»å®ç°** (2-3 å‘¨):
1. **DQN** (Week 1-2: Refactoring) - RL baseline
2. **Rule-based Baselines** (Week 3: 1.5 days)
   - Strongest RSRPï¼ˆç®€å•å¯å‘å¼ - lower boundï¼‰
   - A4-based Strategyï¼ˆ3GPP A4 event + RSRP selection - validated for LEOï¼‰
   - D2-based Strategyï¼ˆ3GPP D2 event + distance selection - NTN-specificï¼‰â­

**é‡è¦è¯´æ˜**: A4/D2 Event æœ¬èº«åªæ˜¯ 3GPP å®šä¹‰çš„æµ‹é‡æŠ¥å‘Šè§¦å‘æ¡ä»¶ï¼ˆæ¥æº: 3GPP TS 38.331ï¼‰ã€‚ä½œä¸º baseline strategyï¼Œæˆ‘ä»¬è¡¥å……äº†ï¼š
- é€‰æ‹©é€»è¾‘ï¼ˆä»å€™é€‰ä¸­é€‰æ‹©å“ªä¸€ä¸ªï¼‰
- åˆ‡æ¢å†³ç­–ï¼ˆæ˜¯å¦çœŸçš„æ‰§è¡Œåˆ‡æ¢ï¼‰

**ç†ç”±**:
- âœ… DQN: å­¦æœ¯ç•Œæ ‡å‡† RL baselineï¼ˆ10+ ç¯‡è®ºæ–‡ï¼‰
- âœ… å¤§éƒ¨åˆ†è«–æ–‡åªç”¨ **1 å€‹ RL baseline** + Rule-based baselines
- âœ… é‡é»æ˜¯å»ºç«‹ **å®Œæ•´çš„ baseline æ¡†æ¶**ï¼Œä¸æ˜¯è­‰æ˜å“ªå€‹ç®—æ³•æœ€å¥½
- âœ… æ¡†æ¶å®Œæˆå¾Œå¯è¼•é¬†åŠ å…¥æ–°ç®—æ³•é€²è¡Œå°æ¯”

**Baseline æ¡†æ¶åŒ…å«**:
- 1 ä¸ª RL baselineï¼ˆDQNï¼‰
- 3 ä¸ª rule-based baselines
- **æä¾›å…¨é¢çš„ç®—æ³•å°æ¯”åŸºç¤ï¼**

---

### ğŸ¯ æ¡†æ¶æ“´å±•æ€§èªªæ˜

**æ¡†æ¶è¨­è¨ˆ**:
- âœ… æ”¯æ´è¼•é¬†åŠ å…¥æ–°ç®—æ³•ï¼ˆå¯¦ç¾ BaseAgent æ¥å£å³å¯ï¼‰
- âœ… çµ±ä¸€è©•ä¼°æ¡†æ¶ï¼ˆRL + Rule-basedï¼‰

**æœªä¾†å°æ¯”**:
- â­ **ç”¨æˆ¶è‡ªå·±çš„ç®—æ³•** vs DQN + 3 Rule-based baselines
- âŒ ä¸éœ€è¦å¯¦ç¾ Tier 2 çš„å…¶ä»– RL ç®—æ³•ï¼ˆD3QNã€A2Cã€Rainbowã€SACï¼‰

**Tier 2 åƒè€ƒ**:
- ä¸Šè¿° Tier 2 ç®—æ³•åƒ…ç‚ºæ–‡ç»èª¿ç ”çµæœ
- ä¾›äº†è§£é ˜åŸŸç ”ç©¶ç¾ç‹€ï¼ˆå“ªäº›ç®—æ³•è¢«ç”¨æ–¼ LEO satellite handoverï¼‰
- ä¸åœ¨æœ¬é …ç›®å¯¦æ–½ç¯„åœå…§

---

## ğŸ“š å…³é”®è®ºæ–‡ç´¢å¼•

### DQN ç›¸å…³ï¼ˆåŸºç¡€ç†è®ºï¼‰
1. Mnih et al. (2015) - "Human-level control through deep reinforcement learning" *Nature*
2. Van Hasselt et al. (2016) - "Deep RL with Double Q-learning" *AAAI*
3. Wang et al. (2016) - "Dueling Network Architectures" *ICML*

### LEO Satellite Handover Applicationsï¼ˆå·²éªŒè¯ï¼‰
4. **Deep Q-Learning for Spectral Coexistence (2025-01)** *IEEE*
   - DQN for LEO/MEO handover

5. **Graph RL-Based Handover (2024-07)** *MDPI Aerospace*
   - MPNN-DQN for LEO handover

6. **Routing Cost-Integrated Handover Strategy (2024-10)** *Chinese Journal of Aeronautics*
   - D3QN for multi-layer LEO mega-constellation â­

7. **Nash-SAC for LEO Satellite Handover (2024-02)** *arXiv*
   - SAC for handover optimization

8. **Joint Traffic Prediction with Rainbow DQN (2024)** *MDPI Electronics*
   - Rainbow DQN for handover + traffic prediction

9. **LEO Satellite Handover Using A2C (2025)** *Conference*
   - A2C for giant constellation handover

10. **Handover Protocol Learning (2023)** *IEEE TWC*
    - IMPALA > DQN > A3C > PPO

### Satellite Schedulingï¼ˆé Handoverï¼‰
11. Frontiers (2023) - "Comparative analysis of RL algorithms for satellite **scheduling**"
    - âš ï¸ PPO ç”¨äº schedulingï¼Œä¸æ˜¯ handover

### Traditional Baselines
12. 3GPP TS 38.331 - A3/A4/A5/D2 äº‹ä»¶å®šä¹‰

---

## âœ… éªŒæ”¶æ ‡å‡†

### æ¯ä¸ªç®—æ³•å¿…é¡»æ»¡è¶³
- [ ] å®ç°å®Œæ•´ï¼ˆæ— ç®€åŒ–ç®—æ³•ï¼‰
- [ ] å¯è®­ç»ƒå¹¶æ”¶æ•›
- [ ] Level 1 æµ‹è¯•é€šè¿‡ï¼ˆ100 episodes, 2 hoursï¼‰
- [ ] Level 3 éªŒè¯ï¼ˆ500 episodes, 10 hoursï¼‰
- [ ] ä¸æ–‡çŒ®æè¿°ä¸€è‡´
- [ ] æœ‰è¯¦ç»†æ–‡æ¡£è¯´æ˜

### å¯¹æ¯”å®éªŒè¦æ±‚
- [ ] ç›¸åŒéšæœºç§å­ï¼ˆå¯é‡ç°ï¼‰
- [ ] ç›¸åŒè®­ç»ƒæ•°æ®ï¼ˆå…¬å¹³å¯¹æ¯”ï¼‰
- [ ] ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒï¼ˆt-test, p<0.05ï¼‰
- [ ] å¯è§†åŒ–å¯¹æ¯”ï¼ˆreward æ›²çº¿ã€handover é¢‘ç‡ç­‰ï¼‰

---

## ğŸ” æ–‡çŒ®éªŒè¯æ–¹æ³•

æœ¬æ–‡æ¡£çš„æ‰€æœ‰ç»“è®ºåŸºäº:
1. âœ… WebSearch æŸ¥è¯¢å®é™…è®ºæ–‡
2. âœ… ç¡®è®¤ç®—æ³•ç”¨äº handoverï¼ˆä¸æ˜¯ scheduling/caching/routingï¼‰
3. âœ… åŒºåˆ† "æœ‰è®ºæ–‡" vs "ç”¨äº handover"
4. âœ… æ£€æŸ¥è®ºæ–‡å‘è¡¨æ—¶é—´å’Œæ¥æº

**éªŒè¯æ—¥æœŸ**: 2025-10-19
**éªŒè¯å·¥å…·**: WebSearch (claude-code)
**æŸ¥è¯¢å…³é”®è¯**: "PPO LEO satellite handover", "D3QN routing cost handover", "A2C LEO handover", etc.

---

**Date**: 2025-10-19
**Last Updated**: 2025-10-20 (å»ºç«‹ Baseline æ¡†æ¶)
**Status**: âœ… æ–‡çŒ®éªŒè¯å®Œæˆï¼ŒBaseline æ¡†æ¶è¦åŠƒå®Œæˆ
**References**: 12 ç¯‡è®ºæ–‡ï¼ˆ2023-2025ï¼Œå·²éªŒè¯ç”¨äº handoverï¼‰
**Next**: å¼€å§‹ Phase 1 - DQN é‡æ„ï¼Œç„¶å Phase 2 - Rule-based Baselines

**ç›®æ¨™**: å»ºç«‹åŒ…å« DQN (RL baseline) å’Œ 3 å€‹ rule-based baselines çš„å®Œæ•´æ¡†æ¶ï¼Œä½œç‚ºæœªä¾†ç®—æ³•å°æ¯”çš„åŸºç¤ã€‚

**Note**: å¤§éƒ¨åˆ†è«–æ–‡åªç”¨ 1 å€‹ RL baseline + Rule-based baselinesã€‚æ¡†æ¶è¨­è¨ˆæ”¯æ´æœªä¾†è¼•é¬†åŠ å…¥æ–°ç®—æ³•ï¼ˆå¦‚ D3QN, A2C ç­‰ï¼‰é€²è¡Œå°æ¯”ã€‚
